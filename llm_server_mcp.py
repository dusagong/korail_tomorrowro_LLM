"""
EXAONE-3.5-32B Server with MCP Host functionality
LLMì´ MCP ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  í˜¸ì¶œí•˜ëŠ” ê¸°ëŠ¥ í¬í•¨
"""
from transformers import AutoModelForCausalLM, AutoTokenizer
from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn
import torch
import httpx
import json
import asyncio
import os
import re
from typing import Optional

app = FastAPI(title="EXAONE-3.5-32B Server + MCP Host")

# ========== MCP Server ì„¤ì • ==========
MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://localhost:8000")

# ========== ëª¨ë¸ ë¡œë”© ==========
print("Loading model...")
model_id = "LGAI-EXAONE/EXAONE-3.5-32B-Instruct"

print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA device: {torch.cuda.get_device_name(0)}")

tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    model_id,
    dtype=torch.bfloat16,
    trust_remote_code=True,
    device_map="auto",
    max_memory={0: "100GiB", "cpu": "50GiB"},
    offload_buffers=True,
)

device = next(model.parameters()).device
print(f"Model loaded! Device: {device}")

# ========== MCP ë„êµ¬ ì •ì˜ (tour-mcp-server ê¸°ì¤€) ==========
MCP_TOOLS = [
    {
        "name": "get_area_codes",
        "description": "ì§€ì—­ì½”ë“œ/ì‹œêµ°êµ¬ì½”ë“œ ëª©ë¡ ì¡°íšŒ",
        "parameters": {"area_code": "ì„ íƒ - ì§€ì—­ì½”ë“œ"}
    },
    {
        "name": "search_by_area",
        "description": "ì§€ì—­ê¸°ë°˜ ê´€ê´‘ì •ë³´ ê²€ìƒ‰. íŠ¹ì • ì§€ì—­ì˜ ê´€ê´‘ì§€, ìŒì‹ì , ìˆ™ë°• ë“± ì¡°íšŒ",
        "parameters": {
            "area_code": "í•„ìˆ˜ - ì§€ì—­ì½”ë“œ",
            "content_type_id": "ì„ íƒ - ì½˜í…ì¸ íƒ€ì…",
            "sigungu_code": "ì„ íƒ - ì‹œêµ°êµ¬ì½”ë“œ",
            "num_of_rows": "ì„ íƒ - ê²°ê³¼ê°œìˆ˜"
        }
    },
    {
        "name": "search_by_keyword",
        "description": "í‚¤ì›Œë“œë¡œ ê´€ê´‘ì •ë³´ ê²€ìƒ‰. ê°€ì¥ ìœ ì—°í•œ ê²€ìƒ‰ ë°©ë²•",
        "parameters": {
            "keyword": "í•„ìˆ˜ - ê²€ìƒ‰í‚¤ì›Œë“œ",
            "area_code": "ì„ íƒ - ì§€ì—­ì½”ë“œ",
            "content_type_id": "ì„ íƒ - ì½˜í…ì¸ íƒ€ì…",
            "num_of_rows": "ì„ íƒ - ê²°ê³¼ê°œìˆ˜"
        }
    },
    {
        "name": "search_by_location",
        "description": "GPS ìœ„ì¹˜ ê¸°ë°˜ ì£¼ë³€ ê´€ê´‘ì •ë³´ ê²€ìƒ‰",
        "parameters": {
            "map_x": "í•„ìˆ˜ - ê²½ë„",
            "map_y": "í•„ìˆ˜ - ìœ„ë„",
            "radius": "ì„ íƒ - ë°˜ê²½(ë¯¸í„°)",
            "content_type_id": "ì„ íƒ - ì½˜í…ì¸ íƒ€ì…"
        }
    },
    {
        "name": "search_festivals",
        "description": "ì¶•ì œ/í–‰ì‚¬ ì •ë³´ ê²€ìƒ‰",
        "parameters": {
            "event_start_date": "í•„ìˆ˜ - ì‹œì‘ì¼(YYYYMMDD)",
            "event_end_date": "ì„ íƒ - ì¢…ë£Œì¼(YYYYMMDD)",
            "area_code": "ì„ íƒ - ì§€ì—­ì½”ë“œ"
        }
    },
    {
        "name": "search_stays",
        "description": "ìˆ™ë°• ì •ë³´ ê²€ìƒ‰",
        "parameters": {
            "area_code": "ì„ íƒ - ì§€ì—­ì½”ë“œ",
            "sigungu_code": "ì„ íƒ - ì‹œêµ°êµ¬ì½”ë“œ"
        }
    },
    {
        "name": "get_detail_common",
        "description": "ê´€ê´‘ì§€ ìƒì„¸ì •ë³´ ì¡°íšŒ (ì£¼ì†Œ, ì´ë¯¸ì§€, ê°œìš” ë“±)",
        "parameters": {
            "content_id": "í•„ìˆ˜ - ì½˜í…ì¸ ID",
            "content_type_id": "í•„ìˆ˜ - ì½˜í…ì¸ íƒ€ì…"
        }
    },
    {
        "name": "get_detail_intro",
        "description": "ê´€ê´‘ì§€ ì†Œê°œì •ë³´ ì¡°íšŒ (ìš´ì˜ì‹œê°„, ì…ì¥ë£Œ ë“±)",
        "parameters": {
            "content_id": "í•„ìˆ˜ - ì½˜í…ì¸ ID",
            "content_type_id": "í•„ìˆ˜ - ì½˜í…ì¸ íƒ€ì…"
        }
    },
    {
        "name": "get_detail_images",
        "description": "ê´€ê´‘ì§€ ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ",
        "parameters": {"content_id": "í•„ìˆ˜ - ì½˜í…ì¸ ID"}
    },
    {
        "name": "get_category_codes",
        "description": "ì„œë¹„ìŠ¤ ë¶„ë¥˜ì½”ë“œ ì¡°íšŒ",
        "parameters": {
            "content_type_id": "ì„ íƒ - ì½˜í…ì¸ íƒ€ì…",
            "cat1": "ì„ íƒ - ëŒ€ë¶„ë¥˜",
            "cat2": "ì„ íƒ - ì¤‘ë¶„ë¥˜"
        }
    },
    {
        "name": "get_detail_info",
        "description": "ì†Œê°œì •ë³´ ì¡°íšŒ (ë°˜ë³µì •ë³´)",
        "parameters": {
            "content_id": "í•„ìˆ˜ - ì½˜í…ì¸ ID",
            "content_type_id": "í•„ìˆ˜ - ì½˜í…ì¸ íƒ€ì…"
        }
    },
    {
        "name": "get_pet_tour_info",
        "description": "ë°˜ë ¤ë™ë¬¼ ì—¬í–‰ì •ë³´ ì¡°íšŒ",
        "parameters": {
            "area_code": "ì„ íƒ - ì§€ì—­ì½”ë“œ",
            "sigungu_code": "ì„ íƒ - ì‹œêµ°êµ¬ì½”ë“œ"
        }
    }
]

# ì§€ì—­ì½”ë“œ ë§¤í•‘
AREA_CODES = {
    "ì„œìš¸": "1", "ì¸ì²œ": "2", "ëŒ€ì „": "3", "ëŒ€êµ¬": "4", "ê´‘ì£¼": "5",
    "ë¶€ì‚°": "6", "ìš¸ì‚°": "7", "ì„¸ì¢…": "8", "ê²½ê¸°": "31", "ê°•ì›": "32",
    "ì¶©ë¶": "33", "ì¶©ë‚¨": "34", "ê²½ë¶": "35", "ê²½ë‚¨": "36",
    "ì „ë¶": "37", "ì „ë‚¨": "38", "ì œì£¼": "39"
}

CONTENT_TYPES = {
    "ê´€ê´‘ì§€": "12", "ë¬¸í™”ì‹œì„¤": "14", "ì¶•ì œ": "15", "ì—¬í–‰ì½”ìŠ¤": "25",
    "ë ˆí¬ì¸ ": "28", "ìˆ™ë°•": "32", "ì‡¼í•‘": "38", "ìŒì‹ì ": "39", "ì¹´í˜": "39"
}

# Need íƒ€ì… â†’ Content Type ë§¤í•‘
NEED_TO_CONTENT_TYPE = {
    "food": "39",      # ìŒì‹ì 
    "cafe": "39",      # ì¹´í˜ (ìŒì‹ì ê³¼ ë™ì¼)
    "spot": "12",      # ê´€ê´‘ì§€
    "stay": "32",      # ìˆ™ë°•
    "culture": "14",   # ë¬¸í™”ì‹œì„¤
    "shopping": "38",  # ì‡¼í•‘
    "festival": "15",  # ì¶•ì œ
}

# ìµœì†Œ ê²°ê³¼ ê°œìˆ˜ ê¸°ì¤€
MIN_RESULTS_THRESHOLD = 3


# ========== Request/Response ëª¨ë¸ ==========
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    model: str = "LGAI-EXAONE/EXAONE-3.5-32B-Instruct"
    messages: list[ChatMessage]
    max_tokens: int = 512
    temperature: float = 0.7

class MCPQueryRequest(BaseModel):
    query: str  # ìì—°ì–´ ì¿¼ë¦¬: "ê°•ë¦‰ ë°”ë‹¤ ê·¼ì²˜ ë§›ì§‘ ì¶”ì²œí•´ì¤˜"
    area_code: Optional[str] = None  # ëª¨ë°”ì¼ì—ì„œ ì„ íƒí•œ ë„ ì½”ë“œ (ì˜ˆ: "32" for ê°•ì›)
    sigungu_code: Optional[str] = None  # ëª¨ë°”ì¼ì—ì„œ ì„ íƒí•œ ì‹œ/êµ°/êµ¬ ì½”ë“œ
    max_tokens: int = 1024
    temperature: float = 0.3


# ========== LLM ìƒì„± í•¨ìˆ˜ ==========
def generate_response(messages: list[dict], max_tokens: int = 512, temperature: float = 0.7) -> str:
    input_text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    inputs = tokenizer(input_text, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            temperature=temperature,
            do_sample=temperature > 0,
            pad_token_id=tokenizer.eos_token_id,
        )

    return tokenizer.decode(
        outputs[0][inputs.input_ids.shape[1]:],
        skip_special_tokens=True
    )


# ========== MCP ë„êµ¬ í˜¸ì¶œ ==========
async def call_mcp_tool(tool_name: str, arguments: dict) -> dict:
    """MCP ì„œë²„ì˜ ë„êµ¬ í˜¸ì¶œ (HTTP API)"""
    async with httpx.AsyncClient(timeout=30) as client:
        try:
            response = await client.post(
                f"{MCP_SERVER_URL}/api/call_tool",
                json={"name": tool_name, "arguments": arguments}
            )
            result = response.json()
            if result.get("success"):
                return result.get("result", {})
            else:
                return {"error": result.get("error", "Unknown error")}
        except Exception as e:
            return {"error": str(e)}


async def call_mcp_tool_direct(tool_name: str, arguments: dict) -> dict:
    """MCP ì„œë²„ ì§ì ‘ í˜¸ì¶œ (HTTP API)"""
    # tour-mcp-serverì˜ í•¨ìˆ˜ë¥¼ ì§ì ‘ HTTPë¡œ í˜¸ì¶œ
    # FastMCPëŠ” ê¸°ë³¸ì ìœ¼ë¡œ stdioì§€ë§Œ, HTTP wrapper ì¶”ê°€ í•„ìš”

    # ì„ì‹œ: ì§ì ‘ Tour API í˜¸ì¶œ
    async with httpx.AsyncClient(timeout=30) as client:
        base_url = "https://apis.data.go.kr/B551011/KorService2"
        api_key = os.getenv("TOUR_API_KEY", "")

        common_params = {
            "serviceKey": api_key,
            "MobileOS": "ETC",
            "MobileApp": "TravelMCP",
            "_type": "json",
            "numOfRows": arguments.get("num_of_rows", 20),
            "arrange": arguments.get("arrange", "B")  # ê¸°ë³¸ê°’: ì¡°íšŒìˆœ(ì¸ê¸°ìˆœ)
        }

        endpoint_map = {
            "get_area_codes": "areaCode2",
            "search_by_area": "areaBasedList2",
            "search_by_keyword": "searchKeyword2",
            "search_by_location": "locationBasedList2",
            "search_festivals": "searchFestival2",
            "search_stays": "searchStay2",
            "get_detail_common": "detailCommon2",
            "get_detail_intro": "detailIntro2",
            "get_detail_images": "detailImage2",
        }

        endpoint = endpoint_map.get(tool_name)
        if not endpoint:
            return {"error": f"Unknown tool: {tool_name}"}

        params = {**common_params}

        # íŒŒë¼ë¯¸í„° ë§¤í•‘
        if "area_code" in arguments:
            params["areaCode"] = arguments["area_code"]
        if "sigungu_code" in arguments:
            params["sigunguCode"] = arguments["sigungu_code"]
        if "content_type_id" in arguments:
            params["contentTypeId"] = arguments["content_type_id"]
        if "keyword" in arguments:
            params["keyword"] = arguments["keyword"]
        if "map_x" in arguments:
            params["mapX"] = arguments["map_x"]
        if "map_y" in arguments:
            params["mapY"] = arguments["map_y"]
        if "radius" in arguments:
            params["radius"] = arguments["radius"]
        if "event_start_date" in arguments:
            params["eventStartDate"] = arguments["event_start_date"]
        if "content_id" in arguments:
            params["contentId"] = arguments["content_id"]
            params["defaultYN"] = "Y"
            params["firstImageYN"] = "Y"
            params["addrinfoYN"] = "Y"
            params["overviewYN"] = "Y"

        try:
            response = await client.get(f"{base_url}/{endpoint}", params=params)
            data = response.json()

            if data["response"]["header"]["resultCode"] != "0000":
                return {"error": data["response"]["header"]["resultMsg"]}

            items = data["response"]["body"].get("items", {})
            if not items:
                return {"items": [], "totalCount": 0}

            item_list = items.get("item", [])
            if isinstance(item_list, dict):
                item_list = [item_list]

            return {
                "items": item_list[:20],  # ìµœëŒ€ 20ê°œ
                "totalCount": data["response"]["body"].get("totalCount", len(item_list))
            }
        except Exception as e:
            return {"error": str(e)}


# ========== ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í—¬í¼ í•¨ìˆ˜ ==========
async def search_by_keyword_direct(keyword: str, area_code: str, sigungu_code: str, content_type_id: str = None, num_rows: int = 20) -> dict:
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ì§ì ‘ í˜¸ì¶œ"""
    args = {
        "keyword": keyword,
        "area_code": area_code,
        "num_of_rows": num_rows
    }
    if sigungu_code:
        args["sigungu_code"] = sigungu_code
    if content_type_id:
        args["content_type_id"] = content_type_id

    return await call_mcp_tool_direct("search_by_keyword", args)


async def search_by_area_direct(area_code: str, sigungu_code: str, content_type_id: str = None, num_rows: int = 20, arrange: str = "B") -> dict:
    """ì§€ì—­ ê¸°ë°˜ ê²€ìƒ‰ ì§ì ‘ í˜¸ì¶œ

    arrange ì˜µì…˜:
    - A: ì œëª©ìˆœ (ê¸°ë³¸)
    - B: ì¡°íšŒìˆœ (ì¸ê¸°ìˆœ) â­ ì¶”ì²œ
    - C: ìˆ˜ì •ì¼ìˆœ
    - D: ìƒì„±ì¼ìˆœ
    """
    args = {
        "area_code": area_code,
        "num_of_rows": num_rows,
        "arrange": arrange  # ì¸ê¸°ìˆœ ì •ë ¬
    }
    if sigungu_code:
        args["sigungu_code"] = sigungu_code
    if content_type_id:
        args["content_type_id"] = content_type_id

    return await call_mcp_tool_direct("search_by_area", args)


def analyze_query_needs(query: str) -> dict:
    """ì¿¼ë¦¬ì—ì„œ í•„ìš”í•œ ê²ƒë“¤ì„ ë¶„ì„ (LLM ì—†ì´ ê·œì¹™ ê¸°ë°˜)

    Returns:
        dict: {
            "food": ["ë§›ì§‘", "ëˆê¹ŒìŠ¤"],  # ì¼ë°˜ + êµ¬ì²´ì  í‚¤ì›Œë“œ
            "food_specific": ["ëˆê¹ŒìŠ¤"],  # êµ¬ì²´ì ì¸ ìŒì‹ë§Œ (ì§ì ‘ ê²€ìƒ‰ìš©)
            "cafe": ["ì¹´í˜"],
            ...
        }
    """
    query_lower = query.lower()
    needs = {}

    # êµ¬ì²´ì ì¸ ìŒì‹ í‚¤ì›Œë“œ (API í‚¤ì›Œë“œ ê²€ìƒ‰ì— ì§ì ‘ ì‚¬ìš©)
    specific_food_keywords = [
        "ëˆê¹ŒìŠ¤", "ëˆê°€ìŠ¤", "ì‚¼ê²¹ì‚´", "ì¹˜í‚¨", "í”¼ì", "íŒŒìŠ¤íƒ€", "ìŠ¤í…Œì´í¬",
        "ì´ˆë°¥", "íšŒ", "ë¼ë©˜", "ìš°ë™", "ëƒ‰ë©´", "ë§‰êµ­ìˆ˜", "ì¹¼êµ­ìˆ˜", "ì§œì¥ë©´", "ì§¬ë½•",
        "ë–¡ë³¶ì´", "ìˆœëŒ€", "ê¹€ë°¥", "ë¹„ë¹”ë°¥", "ë¶ˆê³ ê¸°", "ê°ˆë¹„", "ì‚¼ê³„íƒ•", "ì„¤ë íƒ•",
        "ìˆœë‘ë¶€", "ë¶€ëŒ€ì°Œê°œ", "ê°ìíƒ•", "ê³±ì°½", "ì¡±ë°œ", "ë³´ìŒˆ", "ì¹˜ì¦ˆ", "ë²„ê±°", "í–„ë²„ê±°",
        "ì•„ì´ìŠ¤í¬ë¦¼", "ë¹™ìˆ˜", "ì™€í”Œ", "ë§ˆì¹´ë¡±", "ì¼€ì´í¬"
    ]
    specific_matches = [kw for kw in specific_food_keywords if kw in query_lower]
    if specific_matches:
        needs["food_specific"] = specific_matches  # ì§ì ‘ ê²€ìƒ‰ìš©

    # ìŒì‹ ê´€ë ¨ ì¼ë°˜ í‚¤ì›Œë“œ
    food_keywords = ["ë§›ì§‘", "ìŒì‹", "ë°¥", "ì‹ë‹¹", "ë¨¹", "ì ì‹¬", "ì €ë…", "ì•„ì¹¨",
                     "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "ë¶„ì‹", "ê³ ê¸°", "í•´ì‚°ë¬¼"]
    food_matches = [kw for kw in food_keywords if kw in query_lower]
    if food_matches or specific_matches:
        needs["food"] = food_matches + specific_matches

    # ì¹´í˜ ê´€ë ¨ í‚¤ì›Œë“œ
    cafe_keywords = ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë¹µ", "ë² ì´ì»¤ë¦¬", "ë¸ŒëŸ°ì¹˜", "ì°¨", "ìŒë£Œ"]
    cafe_matches = [kw for kw in cafe_keywords if kw in query_lower]
    if cafe_matches:
        needs["cafe"] = cafe_matches

    # ê´€ê´‘ì§€ ê´€ë ¨ í‚¤ì›Œë“œ
    spot_keywords = ["ê´€ê´‘", "ëª…ì†Œ", "ë³¼ê±°ë¦¬", "êµ¬ê²½", "ë°”ë‹¤", "ì‚°", "ê³µì›", "í•´ë³€", "ì „ë§", "ì•¼ê²½",
                     "ì‚¬ì§„", "ì¸ìŠ¤íƒ€", "ë°ì´íŠ¸", "ë“œë¼ì´ë¸Œ", "ìì—°", "í’ê²½", "ê²½ì¹˜"]
    spot_matches = [kw for kw in spot_keywords if kw in query_lower]
    if spot_matches:
        needs["spot"] = spot_matches

    # ìˆ™ë°• ê´€ë ¨ í‚¤ì›Œë“œ
    stay_keywords = ["ìˆ™ì†Œ", "í˜¸í…”", "íœì…˜", "ëª¨í…”", "ìˆ™ë°•", "ì ", "ë¬µ", "ë¦¬ì¡°íŠ¸", "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤"]
    stay_matches = [kw for kw in stay_keywords if kw in query_lower]
    if stay_matches:
        needs["stay"] = stay_matches

    # ë¬¸í™”ì‹œì„¤ ê´€ë ¨ í‚¤ì›Œë“œ
    culture_keywords = ["ë°•ë¬¼ê´€", "ë¯¸ìˆ ê´€", "ì „ì‹œ", "ê³µì—°", "ì˜í™”", "ë¬¸í™”", "ì—­ì‚¬"]
    culture_matches = [kw for kw in culture_keywords if kw in query_lower]
    if culture_matches:
        needs["culture"] = culture_matches

    # ì•„ë¬´ê²ƒë„ ë§¤ì¹­ ì•ˆë˜ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ê´€ê´‘ì§€ + ìŒì‹ì 
    if not needs:
        needs["spot"] = ["ê´€ê´‘"]
        needs["food"] = ["ë§›ì§‘"]

    print(f"[ORCH] Analyzed needs: {needs}")
    return needs


async def orchestrated_search(query: str, area_code: str, sigungu_code: str, needs: dict) -> dict:
    """
    ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ëœ ê²€ìƒ‰ - í´ë°± ì „ëµ í¬í•¨

    ì „ëµ:
    0. êµ¬ì²´ì ì¸ ìŒì‹ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ê²€ìƒ‰ (ëˆê¹ŒìŠ¤, í”¼ì ë“±)
    1. í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œë„ (ë§¤ì¹­ëœ í‚¤ì›Œë“œë¡œ)
    2. ê²°ê³¼ ë¶€ì¡±ì‹œ â†’ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
    3. ì—¬ì „íˆ ë¶€ì¡±ì‹œ â†’ ì§€ì—­ ì „ì²´ ê²€ìƒ‰
    """
    all_results = {}
    search_log = []

    # Strategy 0: êµ¬ì²´ì ì¸ ìŒì‹ í‚¤ì›Œë“œ ìµœìš°ì„  ê²€ìƒ‰ (ëˆê¹ŒìŠ¤, í”¼ì ë“±)
    if "food_specific" in needs:
        specific_results = {"items": []}
        for kw in needs["food_specific"]:
            print(f"[ORCH] Strategy 0: SPECIFIC food keyword search '{kw}'")
            result = await search_by_keyword_direct(kw, area_code, sigungu_code, "39")  # ìŒì‹ì 
            items = result.get("items", [])
            search_log.append(f"specific:{kw}â†’{len(items)}ê°œ")
            if items:
                specific_results["items"].extend(items)

        if specific_results["items"]:
            all_results["food_specific"] = specific_results
            print(f"[ORCH] Found {len(specific_results['items'])} specific food items!")

    for need_type, keywords in needs.items():
        # food_specificì€ ì´ë¯¸ ì²˜ë¦¬ë¨
        if need_type == "food_specific":
            continue

        content_type = NEED_TO_CONTENT_TYPE.get(need_type)
        results_for_need = {"items": []}

        # Strategy 1: í‚¤ì›Œë“œ ê²€ìƒ‰ (ë§¤ì¹­ëœ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¡œ)
        if keywords and isinstance(keywords, list):
            for kw in keywords[:2]:  # ìµœëŒ€ 2ê°œ í‚¤ì›Œë“œ ì‹œë„
                print(f"[ORCH] Strategy 1: keyword search '{kw}' for {need_type}")
                result = await search_by_keyword_direct(kw, area_code, sigungu_code, content_type)
                items = result.get("items", [])
                search_log.append(f"keyword:{kw}â†’{len(items)}ê°œ")

                if len(items) >= MIN_RESULTS_THRESHOLD:
                    results_for_need = result
                    break
                elif items:
                    # ë¶€ë¶„ ê²°ê³¼ë¼ë„ ì €ì¥
                    results_for_need["items"].extend(items)

        # Strategy 2: ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ (ê²°ê³¼ ë¶€ì¡±ì‹œ)
        if len(results_for_need.get("items", [])) < MIN_RESULTS_THRESHOLD:
            print(f"[ORCH] Strategy 2: area search with content_type={content_type}")
            result = await search_by_area_direct(area_code, sigungu_code, content_type)
            items = result.get("items", [])
            search_log.append(f"area+type:{content_type}â†’{len(items)}ê°œ")

            if items:
                # ê¸°ì¡´ ê²°ê³¼ì— ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
                existing_ids = {i.get("contentid") for i in results_for_need.get("items", [])}
                for item in items:
                    if item.get("contentid") not in existing_ids:
                        results_for_need["items"].append(item)

        # Strategy 3: ì§€ì—­ ì „ì²´ ê²€ìƒ‰ (ì—¬ì „íˆ ë¶€ì¡±ì‹œ)
        if len(results_for_need.get("items", [])) < MIN_RESULTS_THRESHOLD:
            print(f"[ORCH] Strategy 3: area search without content_type")
            result = await search_by_area_direct(area_code, sigungu_code, None, num_rows=30)
            items = result.get("items", [])
            search_log.append(f"area_onlyâ†’{len(items)}ê°œ")

            if items:
                existing_ids = {i.get("contentid") for i in results_for_need.get("items", [])}
                for item in items:
                    if item.get("contentid") not in existing_ids:
                        results_for_need["items"].append(item)

        all_results[need_type] = results_for_need
        print(f"[ORCH] {need_type}: {len(results_for_need.get('items', []))} items collected")

    # ê²°ê³¼ í•©ì¹˜ê¸° (food_specific ìš°ì„ )
    combined_items = []
    seen_ids = set()

    # 1. êµ¬ì²´ì ì¸ ìŒì‹ ê²€ìƒ‰ ê²°ê³¼ ë¨¼ì € ì¶”ê°€ (ëˆê¹ŒìŠ¤ ê²€ìƒ‰í–ˆìœ¼ë©´ ëˆê¹ŒìŠ¤ì§‘ ë¨¼ì €)
    if "food_specific" in all_results:
        for item in all_results["food_specific"].get("items", []):
            cid = item.get("contentid")
            if cid and cid not in seen_ids:
                seen_ids.add(cid)
                combined_items.append(item)
        print(f"[ORCH] Added {len(combined_items)} specific food items first")

    # 2. ë‚˜ë¨¸ì§€ ê²°ê³¼ ì¶”ê°€
    for need_type, result in all_results.items():
        if need_type == "food_specific":
            continue  # ì´ë¯¸ ì²˜ë¦¬ë¨
        for item in result.get("items", []):
            cid = item.get("contentid")
            if cid and cid not in seen_ids:
                seen_ids.add(cid)
                combined_items.append(item)

    return {
        "items": combined_items,
        "totalCount": len(combined_items),
        "search_log": search_log,
        "needs_analyzed": list(needs.keys())
    }


# ========== LLM ê¸°ë°˜ ë„êµ¬ ì„ íƒ ==========
def select_tools_with_llm(query: str, area_code: Optional[str] = None, sigungu_code: Optional[str] = None) -> list[dict]:
    """LLMì„ ì‚¬ìš©í•´ ì¿¼ë¦¬ì— ë§ëŠ” ë„êµ¬ì™€ íŒŒë¼ë¯¸í„° ì„ íƒ"""

    tools_description = "\n".join([
        f"- {t['name']}: {t['description']}\n  íŒŒë¼ë¯¸í„°: {t['parameters']}" for t in MCP_TOOLS
    ])

    # area_code + sigungu_codeê°€ ì œê³µëœ ê²½ìš° í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ ì£¼ì…
    area_context = ""
    if area_code and sigungu_code:
        area_context = f"""
**ğŸ”´ ë§¤ìš° ì¤‘ìš”: ì‚¬ìš©ìê°€ ì´ë¯¸ ì§€ì—­ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤ ğŸ”´**
- area_code: "{area_code}" (ë„/ê´‘ì—­ì‹œ ì½”ë“œ - ë°˜ë“œì‹œ ì‚¬ìš©)
- sigungu_code: "{sigungu_code}" (ì‹œ/êµ°/êµ¬ ì½”ë“œ - ë°˜ë“œì‹œ ì‚¬ìš©)

**ğŸ”´ area_code + sigungu_codeê°€ ì œê³µë˜ë©´ ë°˜ë“œì‹œ search_by_areaë¥¼ ì‚¬ìš©í•˜ì„¸ìš”! ğŸ”´**
- search_by_areaëŠ” í‚¤ì›Œë“œ ì—†ì´ ì§€ì—­+ì½˜í…ì¸ íƒ€ì…ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤
- argumentsì— area_codeì™€ sigungu_code ë‘˜ ë‹¤ ë°˜ë“œì‹œ í¬í•¨!
- í‚¤ì›Œë“œ ê²€ìƒ‰(search_by_keyword)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
"""

    prompt = f"""ë‹¹ì‹ ì€ ì—¬í–‰ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ ë„êµ¬ ì„ íƒ AIì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , ì ì ˆí•œ ë„êµ¬ì™€ íŒŒë¼ë¯¸í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

{area_context}
## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
{tools_description}

## ì§€ì—­ì½”ë“œ (area_code) - ì‚¬ìš©ìê°€ ì œê³µí•˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì°¸ê³ :
ì„œìš¸=1, ì¸ì²œ=2, ëŒ€ì „=3, ëŒ€êµ¬=4, ê´‘ì£¼=5, ë¶€ì‚°=6, ìš¸ì‚°=7, ì„¸ì¢…=8
ê²½ê¸°=31, ê°•ì›=32, ì¶©ë¶=33, ì¶©ë‚¨=34, ê²½ë¶=35, ê²½ë‚¨=36, ì „ë¶=37, ì „ë‚¨=38, ì œì£¼=39

## ì½˜í…ì¸ íƒ€ì… (content_type_id):
ê´€ê´‘ì§€=12, ë¬¸í™”ì‹œì„¤=14, ì¶•ì œ=15, ì—¬í–‰ì½”ìŠ¤=25, ë ˆí¬ì¸ =28, ìˆ™ë°•=32, ì‡¼í•‘=38, ìŒì‹ì /ì¹´í˜=39

## ì˜ˆì‹œ (area_code + sigungu_code ì œê³µëœ ê²½ìš°) - search_by_area ì‚¬ìš©!:
ì§ˆë¬¸: "ë§›ì§‘ ì¶”ì²œí•´ì¤˜"
ì œê³µëœ area_code: "6", sigungu_code: "7"
ì‘ë‹µ: {{"tools": [{{"name": "search_by_area", "arguments": {{"area_code": "6", "sigungu_code": "7", "content_type_id": "39", "num_of_rows": 20}}}}]}}

ì§ˆë¬¸: "ì¹´í˜ë‘ ê´€ê´‘ì§€ ì•Œë ¤ì¤˜"
ì œê³µëœ area_code: "32", sigungu_code: "1"
ì‘ë‹µ: {{"tools": [{{"name": "search_by_area", "arguments": {{"area_code": "32", "sigungu_code": "1", "content_type_id": "39", "num_of_rows": 15}}}}, {{"name": "search_by_area", "arguments": {{"area_code": "32", "sigungu_code": "1", "content_type_id": "12", "num_of_rows": 15}}}}]}}

ì§ˆë¬¸: "ë°ì´íŠ¸í•˜ê¸° ì¢‹ì€ ê³³"
ì œê³µëœ area_code: "1", sigungu_code: "24"
ì‘ë‹µ: {{"tools": [{{"name": "search_by_area", "arguments": {{"area_code": "1", "sigungu_code": "24", "content_type_id": "12", "num_of_rows": 15}}}}, {{"name": "search_by_area", "arguments": {{"area_code": "1", "sigungu_code": "24", "content_type_id": "39", "num_of_rows": 15}}}}]}}

## ì˜ˆì‹œ (area_codeê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°) - search_by_keyword ì‚¬ìš©:
ì§ˆë¬¸: "ê°•ë¦‰ ë°”ë‹¤ ê·¼ì²˜ ë§›ì§‘ ì¶”ì²œí•´ì¤˜"
ì‘ë‹µ: {{"tools": [{{"name": "search_by_keyword", "arguments": {{"keyword": "ë§›ì§‘", "area_code": "32", "content_type_id": "39", "num_of_rows": 20}}}}]}}

ì§ˆë¬¸: "ë¶€ì‚° í•´ìš´ëŒ€ ìˆ™ë°•"
ì‘ë‹µ: {{"tools": [{{"name": "search_by_keyword", "arguments": {{"keyword": "í•´ìš´ëŒ€", "area_code": "6", "content_type_id": "32", "num_of_rows": 20}}}}]}}

## í•µì‹¬ ê·œì¹™:
1. **area_code + sigungu_codeê°€ ì œê³µë˜ë©´ â†’ search_by_area ì‚¬ìš© (í‚¤ì›Œë“œ ê²€ìƒ‰ ê¸ˆì§€)**
2. **search_by_area ì‚¬ìš©ì‹œ area_codeì™€ sigungu_code ë‘˜ ë‹¤ argumentsì— í•„ìˆ˜ í¬í•¨!**
3. **ì§€ì—­ì½”ë“œê°€ ì—†ìœ¼ë©´ â†’ search_by_keyword ì‚¬ìš© (í‚¤ì›Œë“œëŠ” ê°„ë‹¨í•œ ëª…ì‚¬ 1~2ê°œë§Œ)**
4. ìŒì‹ì /ë§›ì§‘/ì¹´í˜ â†’ content_type_id="39"
5. ìˆ™ë°•/í˜¸í…”/íœì…˜ â†’ content_type_id="32"
6. ê´€ê´‘ì§€/ëª…ì†Œ â†’ content_type_id="12"
7. ì—¬ëŸ¬ ì¢…ë¥˜ ìš”ì²­ì‹œ â†’ ë„êµ¬ë¥¼ ì—¬ëŸ¬ ê°œ ì‚¬ìš©
8. num_of_rowsëŠ” 15~20 ê¶Œì¥

## ì‚¬ìš©ì ì§ˆë¬¸:
{query}

## ì‘ë‹µ (JSONë§Œ ì¶œë ¥, ì„¤ëª… ì—†ì´):
{{"tools": [...]}}"""

    messages = [{"role": "user", "content": prompt}]

    print(f"[MCP DEBUG] Sending prompt to LLM for tool selection...")
    print(f"[MCP DEBUG] area_code={area_code}, sigungu_code={sigungu_code}")

    response = generate_response(messages, max_tokens=500, temperature=0.1)

    # ë””ë²„ê·¸: LLMì˜ raw response ì¶œë ¥
    print(f"[MCP DEBUG] LLM raw response:\n{response}")
    print(f"[MCP DEBUG] Response length: {len(response)}")

    # JSON íŒŒì‹± - ì²« ë²ˆì§¸ ì™„ì „í•œ JSON ê°ì²´ë§Œ ì¶”ì¶œ (bracket counting)
    try:
        json_start = response.find("{")
        if json_start < 0:
            print(f"[MCP DEBUG] No JSON object found in response!")
            return []

        # Bracket countingìœ¼ë¡œ ì²« ë²ˆì§¸ ì™„ì „í•œ JSON ê°ì²´ ì°¾ê¸°
        bracket_count = 0
        json_end = -1
        in_string = False
        escape_next = False

        for i, char in enumerate(response[json_start:], start=json_start):
            if escape_next:
                escape_next = False
                continue
            if char == '\\' and in_string:
                escape_next = True
                continue
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
            if in_string:
                continue
            if char == '{':
                bracket_count += 1
            elif char == '}':
                bracket_count -= 1
                if bracket_count == 0:
                    json_end = i + 1
                    break

        print(f"[MCP DEBUG] JSON range: {json_start} to {json_end}")

        if json_end > json_start:
            json_str = response[json_start:json_end]
            print(f"[MCP DEBUG] Extracted JSON:\n{json_str}")

            # LLMì´ JSONì— ì£¼ì„(//)ì„ í¬í•¨ì‹œí‚¤ëŠ” ê²½ìš°ê°€ ìˆì–´ì„œ ì œê±°
            # ë¬¸ìì—´ ë‚´ë¶€ê°€ ì•„ë‹Œ ì£¼ì„ë§Œ ì œê±° (ë¼ì¸ ëê¹Œì§€)
            json_str_clean = re.sub(r'//[^\n]*', '', json_str)
            # ì‰¼í‘œ ë’¤ì— ë°”ë¡œ }ë‚˜ ]ê°€ ì˜¤ëŠ” ê²½ìš° ìˆ˜ì • (trailing comma)
            json_str_clean = re.sub(r',(\s*[}\]])', r'\1', json_str_clean)
            print(f"[MCP DEBUG] Cleaned JSON:\n{json_str_clean}")

            result = json.loads(json_str_clean)
            tools = result.get("tools", [])
            print(f"[MCP DEBUG] Parsed tools count: {len(tools)}")
            return tools
        else:
            print(f"[MCP DEBUG] Could not find matching closing bracket!")
    except json.JSONDecodeError as e:
        print(f"[MCP DEBUG] JSON parsing error: {e}")
        print(f"[MCP DEBUG] Failed JSON string: {json_str if 'json_str' in locals() else 'N/A'}")

    # íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
    print(f"[MCP DEBUG] Returning empty tools list due to parsing failure")
    return []


def curate_results_with_llm(query: str, tool_results: list[dict]) -> dict:
    """LLMì„ ì‚¬ìš©í•´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ íë ˆì´ì…˜ - spots(ë¦¬ìŠ¤íŠ¸ë·°) + course(ì½”ìŠ¤ë·°) ë¶„ë¦¬"""

    # ê²°ê³¼ ìš”ì•½ (ì¢Œí‘œ ì •ë³´ + cat3 í¬í•¨)
    results_summary = []
    for result in tool_results:
        if "items" in result and result["items"]:
            for item in result["items"][:15]:
                results_summary.append({
                    "title": item.get("title", ""),
                    "addr": item.get("addr1", ""),
                    "type": item.get("contenttypeid", ""),
                    "cat3": item.get("cat3", ""),  # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ (ì¹´í˜ êµ¬ë¶„ìš©)
                    "image": item.get("firstimage", ""),
                    "mapx": item.get("mapx", ""),  # ê²½ë„
                    "mapy": item.get("mapy", ""),  # ìœ„ë„
                    "tel": item.get("tel", ""),
                    "content_id": item.get("contentid", "")
                })

    if not results_summary:
        return {
            "spots": [],
            "course": None,
            "message": "ìš”ì²­í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ì¥ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        }

    prompt = f"""ë‹¹ì‹ ì€ ì½”ë ˆì¼ ë™í–‰ì—´ì°¨ ì—¬í–‰ íë ˆì´í„°ì…ë‹ˆë‹¤.

## ì„œë¹„ìŠ¤ ì»¨í…ìŠ¤íŠ¸:
- ëŒ€ìƒ: **ì»¤í”Œ ì—¬í–‰ê°** (ì½”ë ˆì¼ ë™í–‰ì—´ì°¨ ì„œë¹„ìŠ¤)
- ëª©ì : ê´€ê´‘/ë°ì´íŠ¸
- ë¶„ìœ„ê¸°: ë¡œë§¨í‹±í•˜ê³  íŠ¹ë³„í•œ ì¶”ì–µ ë§Œë“¤ê¸°

## ì‚¬ìš©ì ìš”ì²­:
{query}

## ê²€ìƒ‰ëœ ì¥ì†Œë“¤ (ì´ {len(results_summary)}ê°œ):
{json.dumps(results_summary, ensure_ascii=False, indent=2)}

## ì‘ë‹µ í˜•ì‹ (JSONë§Œ ì¶œë ¥, ì„¤ëª… ì—†ì´):
{{
  "course": {{
    "title": "ì½”ìŠ¤ ì œëª© (ì˜ˆ: ê°•ë¦‰ ë°”ë‹¤í–¥ ë°ì´íŠ¸ ì½”ìŠ¤)",
    "stops": [
      {{
        "order": 1,
        "name": "ì¥ì†Œëª…",
        "address": "ì£¼ì†Œ",
        "mapx": "ê²½ë„ê°’",
        "mapy": "ìœ„ë„ê°’",
        "content_id": "ì½˜í…ì¸ ID",
        "category": "ì¹´í˜/ìŒì‹ì /ê´€ê´‘ì§€/ìˆ™ë°•",
        "time": "ì˜¤ì „ 10ì‹œ",
        "duration": "1ì‹œê°„",
        "reason": "ì»¤í”Œì—ê²Œ ì¶”ì²œí•˜ëŠ” ì´ìœ ",
        "tip": "ë°©ë¬¸ íŒ"
      }}
    ],
    "total_duration": "ì•½ 6ì‹œê°„",
    "summary": "ì½”ìŠ¤ ìš”ì•½ (2-3ë¬¸ì¥, ì»¤í”Œ ì—¬í–‰ ê´€ì )"
  }}
}}

## ê·œì¹™:
- ì‚¬ìš©ì ìš”ì²­ì— ë§ê²Œ 3~6ê°œ ì¥ì†Œë¥¼ **ë™ì„  ìˆœì„œëŒ€ë¡œ** ì„ ì •
- **ì»¤í”Œ ë°ì´íŠ¸ ê´€ì **ì—ì„œ ì¶”ì²œ ì´ìœ  ì‘ì„±
- mapx, mapy ê°’ì´ ìˆëŠ” ì¥ì†Œ ìš°ì„  ì„ íƒ (ì§€ë„ ì—°ë™ìš©)
- content_id ë°˜ë“œì‹œ í¬í•¨ (ìƒì„¸ì •ë³´ ì¡°íšŒìš©)
- ì¤‘ë³µ/ë¹„ìŠ·í•œ ì¥ì†Œ ì œì™¸
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥"""

    messages = [{"role": "user", "content": prompt}]
    response = generate_response(messages, max_tokens=1500, temperature=0.5)

    print(f"[CURATE DEBUG] LLM response length: {len(response)}")
    print(f"[CURATE DEBUG] LLM response preview: {response[:500]}...")

    # JSON íŒŒì‹± - bracket counting ë°©ì‹ (select_tools_with_llmê³¼ ë™ì¼)
    curated_course = None
    try:
        json_start = response.find("{")
        if json_start < 0:
            print("[CURATE DEBUG] No JSON object found in response!")
        else:
            # Bracket countingìœ¼ë¡œ ì²« ë²ˆì§¸ ì™„ì „í•œ JSON ê°ì²´ ì°¾ê¸°
            bracket_count = 0
            json_end = -1
            in_string = False
            escape_next = False

            for i, char in enumerate(response[json_start:], start=json_start):
                if escape_next:
                    escape_next = False
                    continue
                if char == '\\' and in_string:
                    escape_next = True
                    continue
                if char == '"' and not escape_next:
                    in_string = not in_string
                    continue
                if in_string:
                    continue
                if char == '{':
                    bracket_count += 1
                elif char == '}':
                    bracket_count -= 1
                    if bracket_count == 0:
                        json_end = i + 1
                        break

            print(f"[CURATE DEBUG] JSON range: {json_start} to {json_end}")

            if json_end > json_start:
                json_str = response[json_start:json_end]
                # ì£¼ì„ ì œê±° ë° trailing comma ìˆ˜ì •
                json_str_clean = re.sub(r'//[^\n]*', '', json_str)
                json_str_clean = re.sub(r',(\s*[}\]])', r'\1', json_str_clean)

                parsed = json.loads(json_str_clean)
                curated_course = parsed.get("course")
                print(f"[CURATE DEBUG] Successfully parsed course: {curated_course is not None}")
            else:
                print("[CURATE DEBUG] Could not find matching closing bracket!")
    except json.JSONDecodeError as e:
        print(f"[CURATE DEBUG] JSON parsing error: {e}")
        print(f"[CURATE DEBUG] Failed JSON string: {json_str[:500] if 'json_str' in locals() else 'N/A'}...")

    # spots ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì „ì²´ ê²€ìƒ‰ ê²°ê³¼, ì¢Œí‘œ í¬í•¨)
    spots = []
    for r in results_summary:
        spots.append({
            "name": r["title"],
            "address": r["addr"],
            "category": _get_category_name(r["type"], r.get("cat3")),  # cat3ë¡œ ì¹´í˜/ìŒì‹ì  êµ¬ë¶„
            "image_url": r["image"],
            "mapx": r["mapx"],
            "mapy": r["mapy"],
            "tel": r["tel"],
            "content_id": r["content_id"]
        })

    return {
        "spots": spots,  # ë¦¬ìŠ¤íŠ¸ ë·°ìš© (ì „ì²´)
        "course": curated_course,  # ì½”ìŠ¤ ë·°ìš© (LLM íë ˆì´ì…˜)
        "message": f"{len(spots)}ê°œì˜ ì¥ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
    }


def _get_category_name(content_type_id: str, cat3: str = None) -> str:
    """content_type_id + cat3ë¥¼ ì¹´í…Œê³ ë¦¬ëª…ìœ¼ë¡œ ë³€í™˜

    cat3 ì½”ë“œ (ìŒì‹ì  ì„¸ë¶€ ë¶„ë¥˜):
    - A05020900: ì¹´í˜/ì „í†µì°»ì§‘
    - A05020100: í•œì‹
    - A05020200: ì„œì–‘ì‹ (ëˆê¹ŒìŠ¤, íŒŒìŠ¤íƒ€ ë“±)
    - A05020300: ì¼ì‹
    - A05020400: ì¤‘ì‹
    - A05020700: ì´ìƒ‰ìŒì‹ì 
    """
    # ìŒì‹ì (39)ì¸ ê²½ìš° cat3ë¡œ ì¹´í˜ êµ¬ë¶„
    if content_type_id == "39" and cat3:
        if cat3 == "A05020900":
            return "ì¹´í˜"

    type_map = {
        "12": "ê´€ê´‘ì§€",
        "14": "ë¬¸í™”ì‹œì„¤",
        "15": "ì¶•ì œ/í–‰ì‚¬",
        "25": "ì—¬í–‰ì½”ìŠ¤",
        "28": "ë ˆí¬ì¸ ",
        "32": "ìˆ™ë°•",
        "38": "ì‡¼í•‘",
        "39": "ìŒì‹ì "
    }
    return type_map.get(content_type_id, "ê¸°íƒ€")


# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========
@app.get("/health")
async def health():
    return {"status": "ok", "mcp_enabled": True}

@app.get("/v1/models")
async def models():
    return {
        "object": "list",
        "data": [{"id": "LGAI-EXAONE/EXAONE-3.5-32B-Instruct", "object": "model"}]
    }

@app.post("/v1/chat/completions")
async def chat_completions(request: ChatRequest):
    """ê¸°ì¡´ OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸"""
    messages = [{"role": m.role, "content": m.content} for m in request.messages]
    response_text = generate_response(messages, request.max_tokens, request.temperature)

    return {
        "id": "chatcmpl-1",
        "object": "chat.completion",
        "model": request.model,
        "choices": [{
            "index": 0,
            "message": {"role": "assistant", "content": response_text},
            "finish_reason": "stop"
        }]
    }


@app.post("/v1/mcp/query")
async def mcp_query(request: MCPQueryRequest):
    """
    MCP Host ì—”ë“œí¬ì¸íŠ¸ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë²„ì „)
    ìì—°ì–´ ì¿¼ë¦¬ â†’ ì¿¼ë¦¬ ë¶„ì„ â†’ í´ë°± ì „ëµ ê²€ìƒ‰ â†’ ê²°ê³¼ íë ˆì´ì…˜

    ì‘ë‹µ êµ¬ì¡°:
    - spots: ë¦¬ìŠ¤íŠ¸ ë·°ìš© (ì „ì²´ ê²€ìƒ‰ ê²°ê³¼, ì¢Œí‘œ í¬í•¨)
    - course: ì½”ìŠ¤ ë·°ìš© (LLMì´ íë ˆì´ì…˜í•œ ë™ì„ )
    """
    query = request.query
    area_code = request.area_code
    sigungu_code = request.sigungu_code

    print(f"[MCP-ORCH] Query: {query}, area_code: {area_code}, sigungu_code: {sigungu_code}")

    # area_codeê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ LLM ê¸°ë°˜ ë°©ì‹ ì‚¬ìš©
    if not area_code:
        print("[MCP-ORCH] No area_code, falling back to LLM-based tool selection")
        selected_tools = select_tools_with_llm(query, area_code, sigungu_code)

        if not selected_tools:
            return {
                "success": False,
                "error": "ì ì ˆí•œ ë„êµ¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "query": query,
                "spots": [],
                "course": None
            }

        tool_results = []
        for tool in selected_tools:
            result = await call_mcp_tool(tool.get("name"), tool.get("arguments", {}))
            tool_results.append({"result": result})

        curated = curate_results_with_llm(query, [r["result"] for r in tool_results])
        return {
            "success": True,
            "query": query,
            "spots": curated.get("spots", []),
            "course": curated.get("course"),
            "message": curated.get("message", ""),
            "search_mode": "llm_based"
        }

    # ========== ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ëª¨ë“œ ==========
    print("[MCP-ORCH] Using orchestrated search with fallback strategies")

    # Phase 1: ì¿¼ë¦¬ ë¶„ì„ (ê·œì¹™ ê¸°ë°˜ - ë¹ ë¦„)
    needs = analyze_query_needs(query)
    print(f"[MCP-ORCH] Needs: {needs}")

    # Phase 2: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê²€ìƒ‰ (í´ë°± ì „ëµ í¬í•¨)
    search_result = await orchestrated_search(query, area_code, sigungu_code, needs)
    print(f"[MCP-ORCH] Search result: {search_result.get('totalCount')} items")
    print(f"[MCP-ORCH] Search log: {search_result.get('search_log')}")

    # Phase 3: ê²°ê³¼ ê²€ì¦ - ìµœì†Œ ê¸°ì¤€ ë¯¸ë‹¬ì‹œ ì¶”ê°€ ê²€ìƒ‰
    if search_result.get("totalCount", 0) < MIN_RESULTS_THRESHOLD:
        print("[MCP-ORCH] Results below threshold, doing broad search")
        # ìµœí›„ì˜ ìˆ˜ë‹¨: ì§€ì—­ ì „ì²´ ê²€ìƒ‰
        broad_result = await search_by_area_direct(area_code, sigungu_code, None, num_rows=50)
        if broad_result.get("items"):
            existing_ids = {i.get("contentid") for i in search_result.get("items", [])}
            for item in broad_result["items"]:
                if item.get("contentid") not in existing_ids:
                    search_result["items"].append(item)
            search_result["totalCount"] = len(search_result["items"])
            search_result["search_log"].append(f"broad_fallbackâ†’{len(broad_result['items'])}ê°œ")

    # Phase 4: LLM íë ˆì´ì…˜ (ì½”ìŠ¤ ìƒì„±)
    curated = curate_results_with_llm(query, [search_result])

    return {
        "success": True,
        "query": query,
        "area_code": area_code,
        "sigungu_code": sigungu_code,
        "spots": curated.get("spots", []),
        "course": curated.get("course"),
        "message": curated.get("message", ""),
        "search_mode": "orchestrated",
        "search_log": search_result.get("search_log", []),
        "needs_analyzed": search_result.get("needs_analyzed", [])
    }


@app.get("/v1/mcp/tools")
async def list_mcp_tools():
    """ì‚¬ìš© ê°€ëŠ¥í•œ MCP ë„êµ¬ ëª©ë¡"""
    return {"tools": MCP_TOOLS}


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=30000)
